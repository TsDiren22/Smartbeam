{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 509, y: 829, w: 13, h: 12\n",
      "x: 1381, y: 781, w: 15, h: 13\n",
      "x: 463, y: 287, w: 17, h: 16\n",
      "x: 1408, y: 285, w: 13, h: 14\n",
      "Number of blinking lights: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract ROIs with blinking lights\n",
    "def extract_blinking_lights(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply thresholding to highlight the lights\n",
    "        _, thresholded = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Extract ROIs based on contours\n",
    "        rois = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            w = w + 10\n",
    "            h = h + 10\n",
    "            x = x - 5\n",
    "            y = y - 5\n",
    "            print(f'x: {x}, y: {y}, w: {w}, h: {h}')\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            rois.append(roi)\n",
    "        \n",
    "        return rois\n",
    "\n",
    "# Example usage\n",
    "image_path_newlights = 'labeled_frames_test\\\\test.mp4_00000_2.jpg'\n",
    "image_path_blacklights = 'labeled_frames_fixed\\\\vid9.mp4_00001_4.jpg'\n",
    "image_path_oldlights = 'labeled_frames_test\\\\vid7.mp4_00000_4.jpg'\n",
    "rois = extract_blinking_lights(image_path_blacklights)\n",
    "\n",
    "# Display the original image and extracted ROIs\n",
    "cv2.imshow('Original Image', cv2.imread(image_path_blacklights))\n",
    "light_count = len(rois)\n",
    "for i, roi in enumerate(rois):\n",
    "    cv2.imshow(f'ROI {i+1}', roi)\n",
    "print(f'Number of blinking lights: {light_count}')\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "framelist = []\n",
    "data_folder = 'labeled_frames_fixed'\n",
    "\n",
    "for image_path in glob(os.path.join(data_folder, '*.jpg')):\n",
    "    framelist.append(image_path)\n",
    "\n",
    "# framelist = [\n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00054_2.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00047_0.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00053_3.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00046_2.jpg',\n",
    "#              ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blinking lights: 4\n",
      "(1374, 773, 27, 27)\n",
      "(458, 283, 27, 27)\n",
      "(1403, 280, 23, 24)\n",
      "(504, 824, 23, 22)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_blinking_lights(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply thresholding to highlight the lights\n",
    "        _, thresholded = cv2.threshold(grey, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Extract ROIs based on contours\n",
    "        rois = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            w = w + 20\n",
    "            h = h + 20\n",
    "            x = x - 10\n",
    "            y = y - 10\n",
    "            \n",
    "            rois.append((x,y,w,h))\n",
    "        \n",
    "        return rois\n",
    "\n",
    "def are_similar_coordinates(coord1, coord2):\n",
    "    x1, y1, w1, h1 = coord1\n",
    "    x2, y2, w2, h2 = coord2\n",
    "    \n",
    "    # Adjust these threshold values based on your requirements\n",
    "    position_threshold = 50  # Adjust as needed\n",
    "    size_threshold = 50  # Adjust as needed\n",
    "    \n",
    "    # Check if the coordinates are similar in terms of position and size\n",
    "    position_diff = abs(x1 - x2) + abs(y1 - y2)\n",
    "    size_diff = abs(w1 - w2) + abs(h1 - h2)\n",
    "    \n",
    "    return position_diff < position_threshold and size_diff < size_threshold\n",
    "\n",
    "# Example usage\n",
    "merged_rois = []\n",
    "all_rois = []\n",
    "\n",
    "for image_path in framelist:\n",
    "    rois = extract_blinking_lights(image_path)\n",
    "    for roi in rois:\n",
    "        all_rois.append(roi)\n",
    "        \n",
    "\n",
    "if all_rois is not None:\n",
    "    for roi_coordinates in all_rois:\n",
    "        add_to_merged = True\n",
    "\n",
    "        for (merged_roi, merged_roi_coordinates) in merged_rois:\n",
    "            if are_similar_coordinates(roi_coordinates, merged_roi_coordinates):\n",
    "                add_to_merged = False\n",
    "                break\n",
    "        \n",
    "        if add_to_merged:\n",
    "            merged_rois.append((roi, roi_coordinates))\n",
    "            \n",
    "print(f'Number of blinking lights: {len(merged_rois)}')\n",
    "\n",
    "#print all coordinates\n",
    "for i, (roi, coordinates) in enumerate(merged_rois):\n",
    "    print(coordinates)\n",
    "    #use coordinates to create image roi\n",
    "    x, y, w, h = coordinates\n",
    "    #extract from original image\n",
    "    img = cv2.imread(framelist[0])\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    #display image\n",
    "    cv2.imshow(f'ROI {i}', roi)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video file\n",
    "video_path = './vidscapstone/vid9.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video file is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "rois = merged_rois\n",
    "\n",
    "# Loop through frames\n",
    "while True:\n",
    "    print('________________________________________________________')\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break the loop if the video is finished\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for _, roi in rois:\n",
    "        x, y, w, h = roi\n",
    "        roi_processed = frame[y:y+h, x:x+w]\n",
    "        roi_processed = cv2.resize(roi_processed, (50, 50))\n",
    "        roi_processed = cv2.convertScaleAbs(roi_processed)\n",
    "        roi_processed = np.array(roi_processed)\n",
    "        roi_processed = roi_processed / 255.0\n",
    "        roi_processed = np.expand_dims(roi_processed, axis=0)\n",
    "        pred = model.predict(roi_processed)\n",
    "    #     print(pred)\n",
    "    #     if pred > 0.5:\n",
    "    #         count += 1\n",
    "\n",
    "    #     cv2.imshow(f'ROI {x}, {y}', frame[y:y+h, x:x+w])\n",
    "\n",
    "    #     breaker = False\n",
    "    #     # Press q to exit\n",
    "    #     if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    #         cv2.destroyAllWindows()\n",
    "    #         breaker = True\n",
    "    #         break\n",
    "    #     else:\n",
    "    #         cv2.destroyAllWindows()\n",
    "\n",
    "    # if breaker:\n",
    "    #     break\n",
    "\n",
    "\n",
    "    #frame_to_show = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "    #cv2.imshow(f'Turned on lights {count}', frame_to_show)\n",
    "    \n",
    "    # print(f'Turned on lights: {count}')\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartbeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
