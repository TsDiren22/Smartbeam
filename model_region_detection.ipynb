{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "framelist = []\n",
    "data_folder = 'labeled_frames_fixed'\n",
    "video = './vidscapstone/vid10.mp4'\n",
    "\n",
    "for image_path in glob(os.path.join(data_folder, '*.jpg')):\n",
    "    framelist.append(image_path)\n",
    "\n",
    "# framelist = [\n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00054_2.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00047_0.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00053_3.jpg', \n",
    "#              'labeled_frames_fixed\\\\vid9.mp4_00046_2.jpg',\n",
    "#              ]\n",
    "    \n",
    "# Load model\n",
    "model = tf.keras.models.load_model('testing_binary_class_classification/testing_binary_class_classification_model_Adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_blinking_lights(img):\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image from {image_path}\")\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply thresholding to highlight the lights\n",
    "        _, thresholded = cv2.threshold(grey, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Extract ROIs based on contours\n",
    "        rois = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            w = w + 20\n",
    "            h = h + 20\n",
    "            x = x - 10\n",
    "            y = y - 10\n",
    "            \n",
    "            rois.append((x,y,w,h))\n",
    "        \n",
    "        return rois\n",
    "\n",
    "def are_similar_coordinates(coord1, coord2):\n",
    "    x1, y1, w1, h1 = coord1\n",
    "    x2, y2, w2, h2 = coord2\n",
    "    \n",
    "    # Adjust these threshold values based on your requirements\n",
    "    position_threshold = 50  # Adjust as needed\n",
    "    size_threshold = 50  # Adjust as needed\n",
    "    \n",
    "    # Check if the coordinates are similar in terms of position and size\n",
    "    position_diff = abs(x1 - x2) + abs(y1 - y2)\n",
    "    size_diff = abs(w1 - w2) + abs(h1 - h2)\n",
    "    \n",
    "    return position_diff < position_threshold and size_diff < size_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Duration: 3.13 seconds\n"
     ]
    }
   ],
   "source": [
    "merged_rois = []\n",
    "all_rois = []\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Calculate the duration of the video in seconds\n",
    "video_duration = total_frames / fps\n",
    "\n",
    "print(f\"Video Duration: {video_duration:.2f} seconds\")\n",
    "\n",
    "framelistVideo = []\n",
    "\n",
    "cv2.namedWindow(\"Video Frames\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open the video file.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    rois = extract_blinking_lights(img)\n",
    "    for roi in rois:\n",
    "        all_rois.append(roi)\n",
    "    \n",
    "    framelistVideo.append(img)\n",
    "\n",
    "    cv2.imshow(\"Video Frames\", cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Destroy the OpenCV window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if all_rois is not None:\n",
    "    for roi_coordinates in all_rois:\n",
    "        add_to_merged = True\n",
    "\n",
    "        for merged_roi_coordinates in merged_rois:\n",
    "            if are_similar_coordinates(roi_coordinates, merged_roi_coordinates):\n",
    "                add_to_merged = False\n",
    "                break\n",
    "        \n",
    "        if add_to_merged:\n",
    "            merged_rois.append(roi_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the merged ROIs on the frame\n",
    "for x, y, w, h in merged_rois:\n",
    "    cv2.rectangle(framelistVideo[4], (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Make the frame smaller to fit on the screen\n",
    "f = cv2.resize(framelistVideo[4], (800, 500))\n",
    "# Display the frame\n",
    "cv2.imshow('frame', f)\n",
    "\n",
    "# Delay to allow time for 'q' key to register\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 1, 1], [1, 1, 1, 0], [1, 1, 0, 1], [1, 1, 1, 1], [0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "rois_in_frames = []\n",
    "\n",
    "# Create a window for displaying frames\n",
    "cv2.namedWindow(\"Video Frames with Bounding Boxes\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "for img in framelistVideo:\n",
    "    on_off = []\n",
    "    \n",
    "    for roi_coordinates in merged_rois:\n",
    "        x, y, w, h = roi_coordinates\n",
    "        \n",
    "        # Ensure the ROI coordinates are within the valid range\n",
    "        x = x - 30\n",
    "        y = y - 30\n",
    "        w = w + 60\n",
    "        h = h + 60\n",
    "        \n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Extract the ROI\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "\n",
    "        # Check if the ROI is not empty before further processing\n",
    "        if not roi.size == 0:\n",
    "            # Convert the ROI to grayscale and apply thresholding\n",
    "            grey = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Apply thresholding to highlight the lights\n",
    "            _, thresholded = cv2.threshold(grey, 170, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Find contours in the thresholded image\n",
    "            contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            if len(contours) == 0:\n",
    "                on_off.append(0)\n",
    "            else:\n",
    "                on_off.append(1)\n",
    "        else:\n",
    "            on_off.append(0)  # If the ROI is empty, consider it as lights off\n",
    "    \n",
    "    rois_in_frames.append(on_off)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow(\"Video Frames with Bounding Boxes\", cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Introduce a delay (you can adjust the value as needed)\n",
    "    key = cv2.waitKey(30)\n",
    "\n",
    "    # Check for the 'q' key to exit the loop\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the OpenCV window\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(rois_in_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0), (1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1), (1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1), (0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1)]\n",
      "Frequency of light 93: 5.1063829787234045\n",
      "Frequency of light 93: 5.1063829787234045\n",
      "Frequency of light 93: 5.425531914893617\n",
      "Frequency of light 93: 5.1063829787234045\n"
     ]
    }
   ],
   "source": [
    "# Transpose the array using zip\n",
    "cal_freq = []\n",
    "transposed_array = list(zip(*rois_in_frames))\n",
    "print(transposed_array)\n",
    "for i, separated_array in enumerate(transposed_array):\n",
    "    filtered_tuple = [separated_array[0]] \n",
    "\n",
    "    for i in range(1, len(separated_array)):\n",
    "        if separated_array[i] != separated_array[i - 1]:\n",
    "            filtered_tuple.append(separated_array[i])\n",
    "            \n",
    "    frequency = filtered_tuple.count(1)/video_duration\n",
    "    print(f\"Frequency of light {i}: {frequency}\")\n",
    "    cal_freq.append(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blinking lights: 4\n",
      "(1374, 773, 27, 27)\n",
      "(458, 283, 27, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1403, 280, 23, 24)\n",
      "(504, 824, 23, 22)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of blinking lights: {len(merged_rois)}')\n",
    "\n",
    "#print all coordinates\n",
    "for i, coordinates in enumerate(merged_rois):\n",
    "    print(coordinates)\n",
    "    #use coordinates to create image roi\n",
    "    x, y, w, h = coordinates\n",
    "    #extract from original image\n",
    "    img = cv2.imread(framelist[0])\n",
    "    roi = img[y:y+h, x:x+w]\n",
    "    #display image\n",
    "    cv2.imshow(f'ROI {i}', roi)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "import concurrent.futures\n",
    "\n",
    "global previous_frame\n",
    "\n",
    "# Function to process each ROI\n",
    "def process_roi(roi):\n",
    "\n",
    "    x, y, w, h = roi\n",
    "    x = x - 50\n",
    "    y = y - 50\n",
    "    w = w + 100\n",
    "    h = h + 100\n",
    "    \n",
    "    roi_processed = frame[y:y+h, x:x+w]\n",
    "    roi_processed = cv2.resize(roi_processed, (30, 30), interpolation=cv2.INTER_LINEAR)\n",
    "    roi_processed = cv2.convertScaleAbs(roi_processed)\n",
    "    roi_processed = np.array(roi_processed)\n",
    "    roi_processed = roi_processed / 255.0\n",
    "    roi_processed = np.expand_dims(roi_processed, axis=0)  # Add batch size dimension\n",
    "\n",
    "    roi_processed_prev = previous_frame[y:y+h, x:x+w]\n",
    "    roi_processed_prev = cv2.resize(roi_processed_prev, (30, 30), interpolation=cv2.INTER_LINEAR)\n",
    "    roi_processed_prev = cv2.convertScaleAbs(roi_processed_prev)\n",
    "    roi_processed_prev = np.array(roi_processed_prev)\n",
    "    roi_processed_prev = roi_processed_prev / 255.0\n",
    "    roi_processed_prev = np.expand_dims(roi_processed_prev, axis=0)  # Add batch size dimension\n",
    "    \n",
    "    return np.concatenate((roi_processed, roi_processed_prev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been started.\n",
      "[(1374, 773, 27, 27), (458, 283, 27, 27), (1403, 280, 23, 24), (504, 824, 23, 22)]\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 0: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 5.00 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 2: 5.00 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.67 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 0: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 2: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.33 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 0: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 2: 5.00 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.33 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 0: 4.67 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 1: 4.00 Hz\n",
      "Inconsistencies on light 1 detected! Please check the light.\n",
      "The calculated Frequency is 4.00 Hz, while the expected frequency is 5.43 Hz.\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 2: 4.33 Hz\n",
      "Inconsistencies on light 2 detected! Please check the light.\n",
      "The calculated Frequency is 4.33 Hz, while the expected frequency is 5.74 Hz.\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 3: 4.67 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 0: 5.00 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 2: 5.33 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.00 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 0: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 1: 4.67 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 2: 4.00 Hz\n",
      "Inconsistencies on light 2 detected! Please check the light.\n",
      "The calculated Frequency is 4.00 Hz, while the expected frequency is 5.74 Hz.\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.00 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 0: 3.67 Hz\n",
      "Inconsistencies on light 0 detected! Please check the light.\n",
      "The calculated Frequency is 3.67 Hz, while the expected frequency is 5.11 Hz.\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 1: 3.00 Hz\n",
      "Inconsistencies on light 1 detected! Please check the light.\n",
      "The calculated Frequency is 3.00 Hz, while the expected frequency is 5.43 Hz.\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 2: 3.33 Hz\n",
      "Inconsistencies on light 2 detected! Please check the light.\n",
      "The calculated Frequency is 3.33 Hz, while the expected frequency is 5.74 Hz.\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 3: 3.67 Hz\n",
      "Inconsistencies on light 3 detected! Please check the light.\n",
      "The calculated Frequency is 3.67 Hz, while the expected frequency is 5.74 Hz.\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 0: 5.00 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 4.67 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 2: 4.67 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.00 Hz\n",
      "Predicting next batch of frames...\n",
      "Seconds passed: 3.00\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "3.0\n",
      "Frequency of light 0: 5.00 Hz\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 1: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 2: 5.33 Hz\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "3.0\n",
      "Frequency of light 3: 5.33 Hz\n",
      "Predicting next batch of frames...\n",
      "FPS: 12.539572795760364\n",
      "Total time: 68.8224205 seconds\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "video_path = './vidscapstone/vid11.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Get the frames per second from the video\n",
    "\n",
    "# Initialize roi_frequencies for each ROI\n",
    "roi_frequencies = {i: [] for i in range(len(merged_rois))}\n",
    "reset_interval = 90\n",
    "\n",
    "batch_size = len(merged_rois) * 2\n",
    "frame_count = 0\n",
    "frame_total = 0\n",
    "\n",
    "# Create a window for displaying frames with bounding boxes\n",
    "cv2.namedWindow(\"Processed Video\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "timer = cv2.getTickCount()\n",
    "\n",
    "print(\"Predictions have been started.\")\n",
    "print(merged_rois)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    frame_total += 1\n",
    "\n",
    "    # Draw the merged ROIs on the frame\n",
    "\n",
    "    if frame_count % 2 != 0 and reset_interval != frame_count:\n",
    "        previous_frame = frame.copy()\n",
    "        continue\n",
    "\n",
    "    # Process ROIs sequentially\n",
    "    rois_processed = [process_roi(roi) for roi in merged_rois]\n",
    "    \n",
    "    rois_processed = np.vstack(rois_processed)  # Stack ROIs to create a batch\n",
    "\n",
    "    # Make predictions on the batch of ROIs\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        predictions = model.predict(rois_processed)\n",
    "        \n",
    "    predictions = np.where(predictions > 0.5, 1, 0)\n",
    "    ordered_predictions_1 = []\n",
    "    ordered_predictions_2 = []\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if i % 2 == 0:\n",
    "            ordered_predictions_1.append(prediction)\n",
    "        else:\n",
    "            ordered_predictions_2.append(prediction)\n",
    "\n",
    "    predictions = np.concatenate((ordered_predictions_1, ordered_predictions_2))\n",
    "    \n",
    "    # Draw bounding boxes on the frame\n",
    "    for i, roi_coordinates in enumerate(merged_rois):\n",
    "        x, y, w, h = roi_coordinates\n",
    "\n",
    "        x = x - 50\n",
    "        y = y - 50\n",
    "        w = w + 100\n",
    "        h = h + 100\n",
    "\n",
    "        roi_index = i % len(merged_rois)\n",
    "\n",
    "        if predictions[i][0] == 1:\n",
    "            color = (0, 255, 0)  # Green for lights on\n",
    "        else:\n",
    "            color = (0, 0, 255)  # Red for lights off\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow(\"Processed Video\", cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Introduce a delay (you can adjust the value as needed)\n",
    "    key = cv2.waitKey(30)\n",
    "\n",
    "    # Check for the 'q' key to exit the loop\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Distribute predictions to each ROI\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        roi_index = i % len(merged_rois)\n",
    "        if len(roi_frequencies[roi_index]) == 0 or roi_frequencies[roi_index][-1] != prediction[0]:\n",
    "            roi_frequencies[roi_index].append(prediction[0])\n",
    "\n",
    "    # Reset frequencies after a certain number of frames\n",
    "    if frame_count % reset_interval == 0:\n",
    "        seconds_passed = frame_count / fps\n",
    "        print(f\"Seconds passed: {seconds_passed:.2f}\")\n",
    "        # Calculate the average frequency for each ROI\n",
    "        for i in range(len(merged_rois)):\n",
    "            if len(roi_frequencies[i]) > 0:\n",
    "                frequency = sum(roi_frequencies[i]) / seconds_passed\n",
    "                print(f\"Frequency of light {i}: {frequency:.2f} Hz\")\n",
    "                if frequency < cal_freq[i] - 0.7 or frequency > cal_freq[1] + 0.7:\n",
    "                    print(f\"Inconsistencies on light {i} detected! Please check the light.\")\n",
    "                    print(f\"The calculated Frequency is {frequency:.2f} Hz, while the expected frequency is {cal_freq[i]:.2f} Hz.\")\n",
    "                    with open('logs.txt', 'a') as f:\n",
    "                        f.write(f\"Date & Time: {datetime.now().strftime('%d/%m/%Y, %H:%M:%S')} \\nWarning: Expected frequency of light {i}: {cal_freq[i]:.2f}\\nActual frequency: {frequency:.2f} Hz.\\n\\n\")\n",
    "                        f.close()\n",
    "\n",
    "        roi_frequencies = {i: [] for i in range(len(merged_rois))}\n",
    "        frame_count = 0\n",
    "        print(\"Predicting next batch of frames...\")\n",
    "\n",
    "# Calculate FPS\n",
    "fps = frame_total / ((cv2.getTickCount() - timer) / cv2.getTickFrequency())\n",
    "print(f\"FPS: {fps}\")\n",
    "\n",
    "# Calculate total time\n",
    "total_time = (cv2.getTickCount() - timer) / cv2.getTickFrequency()\n",
    "print(f\"Total time: {total_time} seconds\")\n",
    "cap.release()\n",
    "\n",
    "# Release the OpenCV window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
